{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../Datasets/train.csv'  #paths to data\n",
    "test_path = '../Datasets/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '290', '291', '292', '293', '294', '295', '296', '297', '298', '299'],\n",
       "      dtype='object', length=300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns                      #listing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)                          #load the train data\n",
    "train_df_values = train_df.drop(['id', 'target'], axis = 1)   #retain only required columns for train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df_values.values                                  #convert the df into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_100 = TruncatedSVD(n_components=100, n_iter=20, random_state=42)  #svd object with 100 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=20,\n",
       "       random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_100.fit(X)                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7803804657811666\n"
     ]
    }
   ],
   "source": [
    "print(svd_100.explained_variance_ratio_.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 100 columns explain upto 78% of variance. Let's try 150 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=150, n_iter=20,\n",
       "       random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_150 = TruncatedSVD(n_components=150, n_iter=20, random_state=42)\n",
    "svd_150.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246093979004004\n"
     ]
    }
   ],
   "source": [
    "print(svd_150.explained_variance_ratio_.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150 columns gives about 92% variance which seems enough to achieve a parsimonious model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = svd_150.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_reduced is the new train matrix with 150 columns which explain 92% of the variance. Lasso regression has been the most successful model yet so we will perform lasso regression using this reduced matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(test_path)                 #read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['id'], axis=1)            #load X_test and y_train \n",
    "y_train = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of the code is borrowed from Lasso Regression which can be found in ../3 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 220 candidates, totalling 4400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 319 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 819 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1519 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2419 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3519 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4385 out of 4400 | elapsed:  1.3min remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score obtained is:  0.7017 for the parameters:  {'C': 1, 'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l1'}\n",
      "LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l1', random_state=0,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4400 out of 4400 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "random_state = 0\n",
    "\n",
    "#Hyperparameter = lambda\n",
    "#Using Logistic Regression with l1 regularisation\n",
    "logit = LogisticRegression(random_state=random_state)\n",
    "#Using ROC_AUC score for testing each lambda value\n",
    "rocauc_score = make_scorer(roc_auc_score) \n",
    "#Using GridSearch to search for the best lambda value for the model\n",
    "parameter_grid = {'class_weight':['balanced'], 'penalty' : ['l1', 'l2'], 'C':[0.0001, 0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5, 1,10, 100, 1000, 1500, 2000, 2500,2600, 2700, 2800, 2900, 3000, 3100, 3200],'max_iter' : [100, 1000, 2000, 5000, 10000] }\n",
    "\n",
    "#Grid Search\n",
    "grid = GridSearchCV(estimator=logit,param_grid=parameter_grid,scoring=rocauc_score,verbose=1,cv=20,n_jobs=-1)\n",
    "grid.fit(X_reduced, y_train)\n",
    "best_score = grid.best_score_\n",
    "best_para = grid.best_params_\n",
    "best_logit = grid.best_estimator_\n",
    "#roc_auc Score\n",
    "print(\"Best Score obtained is: \", best_score, \"for the parameters: \", best_para)\n",
    "#Hyperparameters of the best model\n",
    "print(best_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a Logistic Regression Model with l1 Regularisation with the above obtained best hyperparameters\n",
    "model = LogisticRegression(C=1, class_weight='balanced', dual=False,fit_intercept=True, intercept_scaling=1, max_iter=100,multi_class='warn', n_jobs=None, penalty='l1', random_state=0, solver='liblinear', tol=0.0001, verbose=0, warm_start=False);\n",
    "model.fit(X_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score : 100.0 %\n"
     ]
    }
   ],
   "source": [
    "#Train Score on the model\n",
    "score_train = model.score(X_reduced, y_train)\n",
    "print(\"Train Score :\", str(score_train*100)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do svd with same params on  X_test \n",
    "X_test_reduced = svd_150.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the predicted values and testing them on Kaggle to get a score\n",
    "y_pred_logit_lasso = model.predict_proba(X_test_reduced)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_logit_lasso_05 = [1 if x > 0.5 else 0 for x in y_pred_logit_lasso]\n",
    "data = {'id':test['id'], 'target':y_pred_logit_lasso}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('results_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id      0      1      2      3      4      5      6      7      8  \\\n",
      "0        250  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687   \n",
      "1        251  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578 -0.313  0.203   \n",
      "2        252  1.750  0.509 -0.057  0.835 -0.476  1.428 -0.701 -2.009 -1.378   \n",
      "3        253 -0.556 -1.855 -0.682  0.578  1.592  0.512 -1.419  0.722  0.511   \n",
      "4        254  0.754 -0.245  1.173 -1.623  0.009  0.370  0.781 -1.763 -1.432   \n",
      "5        255 -1.650 -0.534 -1.056  2.040  1.479 -0.197 -0.441 -0.557 -0.241   \n",
      "6        256  0.096  0.794 -0.126  0.787  1.187 -0.611  1.383 -0.383 -1.934   \n",
      "7        257 -1.205  0.295 -0.221  0.840  1.545 -0.152  0.373 -0.349 -0.922   \n",
      "8        258 -0.377 -1.135 -1.791 -0.642  0.353 -1.234  0.878 -2.155 -0.542   \n",
      "9        259 -1.731  1.171  0.383 -1.039 -0.091 -0.076  0.244 -1.023 -0.876   \n",
      "10       260  1.208 -2.625 -0.417  1.182  0.151 -0.457 -0.080  1.658 -1.032   \n",
      "11       261 -0.541  0.281 -1.248 -0.069 -1.235 -2.160  0.178  0.829 -0.128   \n",
      "12       262  0.647  0.222  1.297 -1.245  2.809  0.119 -1.457  1.045  1.988   \n",
      "13       263  0.980  2.049 -0.378 -0.028 -0.447 -0.354 -0.965 -0.036  2.473   \n",
      "14       264  0.490 -0.690 -0.015  0.827 -0.669  1.517 -0.755 -0.587  0.142   \n",
      "15       265 -0.156  0.744 -1.683  2.257 -0.234 -0.809 -0.307  0.784 -0.239   \n",
      "16       266 -0.030  0.428 -0.173 -0.421  1.086  1.305 -0.783 -0.087  0.271   \n",
      "17       267  1.092 -0.635 -1.253 -1.998  0.922  0.512 -0.819 -1.463 -1.533   \n",
      "18       268  1.089 -0.465  1.161 -0.701 -0.417  0.484 -1.225 -1.398  1.532   \n",
      "19       269 -1.541  0.133  1.748 -0.334  0.789 -0.405 -0.070 -1.553 -0.006   \n",
      "20       270  0.155  0.549 -0.368 -0.545  0.898  0.255  0.871  0.232 -0.437   \n",
      "21       271 -0.152  0.971  0.686  2.141 -0.607 -0.019 -0.511  1.530  0.810   \n",
      "22       272 -0.739 -0.465 -1.557  0.061 -2.107 -0.067 -1.591  2.061 -1.122   \n",
      "23       273  2.151  0.424 -1.678  1.233  1.248  0.954  1.048 -2.045 -0.467   \n",
      "24       274 -0.367 -0.606 -1.356 -3.510  0.757  0.444  0.839 -1.981 -0.093   \n",
      "25       275 -0.116  0.929 -1.924 -0.671 -0.671  1.215 -0.176 -1.206 -1.135   \n",
      "26       276 -0.632 -1.254  0.280  0.955  0.982  1.399 -1.565 -1.014 -1.884   \n",
      "27       277 -0.685  0.295 -1.175  1.084  1.453  0.173 -0.957 -1.908 -0.412   \n",
      "28       278  1.611  1.685 -0.007  1.808  1.571  0.110 -0.178  0.314 -0.773   \n",
      "29       279  0.975  1.226 -1.266  1.047  0.558  2.231  1.444  0.335 -1.766   \n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "19720  19970  0.414 -0.596  0.082 -0.458  1.284  0.804  1.440  0.983  1.320   \n",
      "19721  19971 -2.124 -0.371  0.116  0.441  0.449  1.321 -0.233  1.542  0.252   \n",
      "19722  19972 -0.363  0.914 -0.898 -1.094 -1.947  0.657  1.323  0.099  2.184   \n",
      "19723  19973 -0.180  0.615  0.998  1.934 -0.230  1.185 -0.379  0.033 -0.231   \n",
      "19724  19974 -0.252  2.050  0.763 -1.245  0.667  0.396 -0.720  1.168 -0.689   \n",
      "19725  19975 -0.508 -0.953  1.933  1.210  0.333 -0.186 -0.447  1.640 -0.413   \n",
      "19726  19976 -2.291 -0.480 -1.511 -0.287  0.821 -0.716  1.282 -0.702 -0.973   \n",
      "19727  19977  2.164 -1.744  0.118  1.009 -1.894 -0.467 -2.025  0.496  1.335   \n",
      "19728  19978  0.556 -0.169 -0.335  1.405  0.240  0.218 -1.402  1.919 -0.734   \n",
      "19729  19979 -1.537 -0.349  0.275 -0.178 -0.512  1.064 -1.576  0.257 -0.730   \n",
      "19730  19980 -1.726  0.623  0.474 -1.308 -0.354  0.799 -0.670  0.590 -1.013   \n",
      "19731  19981 -1.020  0.993  0.930  1.040  2.209  1.503 -2.459  0.315 -1.722   \n",
      "19732  19982  1.018  1.101 -0.645 -1.037 -0.499  0.742  0.434  0.324 -0.935   \n",
      "19733  19983 -0.696  0.428 -1.458 -1.477 -2.982 -0.275 -1.344  1.410 -0.836   \n",
      "19734  19984 -0.197 -1.734 -0.125  1.549  0.616 -0.547 -2.290  1.821 -0.019   \n",
      "19735  19985 -0.222 -0.707 -0.570 -1.565  0.452  0.031  0.314 -1.645  0.019   \n",
      "19736  19986 -0.621 -1.417  1.038  0.309 -1.058 -0.261 -0.059 -1.016  1.599   \n",
      "19737  19987  0.966 -0.576  2.521  2.171  0.229 -0.275  0.392 -0.226  0.909   \n",
      "19738  19988 -0.050  0.597 -1.250 -1.881  0.595  1.110 -0.198 -0.824 -1.131   \n",
      "19739  19989 -0.106 -0.087 -0.429  1.640  1.943 -1.193 -0.993  0.346 -0.905   \n",
      "19740  19990 -1.211 -0.957  0.163  0.166 -0.897  1.573 -0.565  0.979 -0.086   \n",
      "19741  19991  0.347  0.493 -0.225 -2.072  0.040  0.613  0.493 -0.593 -0.717   \n",
      "19742  19992  0.130  1.880  0.409  0.958 -0.815 -1.443  0.900 -0.346  1.149   \n",
      "19743  19993 -1.375  0.549  0.281 -2.122  0.223  0.293  0.478  1.120 -0.508   \n",
      "19744  19994  0.138 -0.954 -0.221  0.024 -1.104 -0.426 -1.481 -1.784 -1.066   \n",
      "19745  19995  1.069  0.517 -0.690  0.241  0.913 -0.859  0.093 -0.359 -0.047   \n",
      "19746  19996 -0.529  0.438  0.672  1.436 -0.720  0.698 -0.350  2.150 -1.241   \n",
      "19747  19997 -0.554 -0.936 -1.427  0.027 -0.539  0.994 -1.832 -1.156  0.474   \n",
      "19748  19998 -0.746  1.205  0.750 -0.236  1.139 -1.727 -0.677 -1.254 -0.099   \n",
      "19749  19999  0.736 -0.216 -0.110 -1.404 -0.265 -1.770  0.715  0.469  1.077   \n",
      "\n",
      "       ...      290    291    292    293    294    295    296    297    298  \\\n",
      "0      ...   -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312   \n",
      "1      ...   -0.683 -0.066  0.025  0.606 -0.353 -1.133 -3.138  0.281 -0.625   \n",
      "2      ...   -0.094  0.351 -0.607 -0.737 -0.031  0.701  0.976  0.135 -1.327   \n",
      "3      ...   -0.336 -0.787  0.255 -0.031 -0.836  0.916  2.411  1.053 -1.601   \n",
      "4      ...    2.184 -1.090  0.216  1.186 -0.143  0.322 -0.068 -0.156 -1.153   \n",
      "5      ...   -0.002 -0.687  0.894  1.187 -1.435 -1.290 -0.515  1.129 -0.823   \n",
      "6      ...   -0.080  0.655  0.793 -1.809 -0.848  1.581 -0.257 -0.447 -0.560   \n",
      "7      ...    2.119  0.620 -0.019 -0.126 -0.864 -0.153  1.747 -0.388  0.946   \n",
      "8      ...    0.349 -0.180  0.728  0.101 -0.586  0.595 -1.374  0.129 -0.580   \n",
      "9      ...   -0.023  0.004  0.589  0.495  1.332  0.254 -0.002  0.657 -0.156   \n",
      "10     ...    0.541 -1.735 -1.349 -1.128  1.001  0.338  0.531  0.771  0.977   \n",
      "11     ...   -0.291  0.994 -1.092  1.215 -1.294 -2.454  0.443  1.296 -0.455   \n",
      "12     ...    1.773 -1.219 -1.637 -0.216 -0.755  0.744  0.191  0.990 -0.078   \n",
      "13     ...    0.151 -1.450  1.391 -0.080 -0.439  1.627  0.267  0.300 -1.144   \n",
      "14     ...   -0.882  0.393  0.531  1.095  2.090 -1.234 -0.054  0.261 -0.442   \n",
      "15     ...    1.138  0.561 -1.010 -0.077 -1.467  2.017  0.344 -0.449  0.836   \n",
      "16     ...   -0.583  0.214 -1.161 -1.599  1.182  0.035 -1.185  1.226 -0.605   \n",
      "17     ...    1.693 -0.067  1.011 -0.011  0.343 -0.059 -2.163  0.311  1.620   \n",
      "18     ...    0.832 -0.419 -0.246 -1.511  0.642  0.302  0.440 -0.901  0.708   \n",
      "19     ...    1.239  0.853 -2.533  2.179 -1.620  0.300  1.316  0.202 -0.139   \n",
      "20     ...    0.620  0.009 -2.061  0.531 -0.642 -0.671  0.737 -0.036  0.596   \n",
      "21     ...    2.004 -0.284 -0.296  0.744 -0.306  1.715  0.018 -1.734  1.044   \n",
      "22     ...    1.044 -0.400  0.156 -1.190 -0.286  0.482 -0.205  1.564  1.189   \n",
      "23     ...    0.554 -0.355  0.527 -0.489  1.062  0.478  0.099 -0.194 -1.300   \n",
      "24     ...    1.005  0.896 -0.002  0.411  0.331  0.196 -0.629  0.694  1.873   \n",
      "25     ...    3.009  0.208 -0.278 -0.828 -0.336  0.529 -0.066  0.227 -1.006   \n",
      "26     ...    0.137  0.646 -2.179 -0.539 -0.395  0.852  1.080 -0.409 -0.020   \n",
      "27     ...    0.394  0.230  0.531  1.030  0.818 -0.861 -0.362  0.403 -0.972   \n",
      "28     ...    0.163 -0.180  0.002  1.872  0.641 -0.122  1.827  1.194  0.169   \n",
      "29     ...    1.318 -2.127  0.669  1.805 -1.358 -0.201 -0.587 -0.527 -0.347   \n",
      "...    ...      ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "19720  ...   -0.371  2.186 -0.823  0.528 -0.427 -0.069 -1.258 -0.332 -0.473   \n",
      "19721  ...    2.238 -0.213  0.138 -1.127 -0.084  0.106  0.771  0.681 -1.953   \n",
      "19722  ...    1.530 -0.159  0.444  1.563 -2.542  1.259 -2.147 -0.460  1.990   \n",
      "19723  ...    1.141 -0.089 -1.107 -0.713 -0.696  0.397  0.357  1.041 -0.369   \n",
      "19724  ...    0.790 -1.387  0.983 -1.035 -1.048  0.190  1.307 -0.075 -0.127   \n",
      "19725  ...   -0.760  0.078  0.738 -0.260 -0.961  0.129 -1.034 -0.759 -0.327   \n",
      "19726  ...   -0.957 -0.848  0.650 -0.119  1.321 -2.172  0.641 -2.175 -1.672   \n",
      "19727  ...   -0.439 -1.458  0.717 -0.666  1.305 -1.532 -1.167 -0.511 -0.506   \n",
      "19728  ...    0.265  1.021  0.665  0.023  0.812 -0.369  0.687 -0.054 -0.118   \n",
      "19729  ...   -1.029  0.389 -0.677 -0.203  0.026 -0.453  0.462 -0.088 -0.058   \n",
      "19730  ...   -1.304  0.410 -0.235  0.071  1.279 -0.954  0.202 -1.352  1.332   \n",
      "19731  ...   -0.090  1.136 -1.579 -0.514  0.726  0.181 -0.356 -0.051  1.035   \n",
      "19732  ...   -0.078 -1.215  1.125 -0.520 -0.088 -0.426  0.225 -0.879  0.085   \n",
      "19733  ...    0.348 -0.129  0.410 -0.066  1.643 -0.243  0.268 -0.753 -0.238   \n",
      "19734  ...   -0.620  0.694 -0.517 -1.444 -1.018 -0.337  0.637  1.474 -0.392   \n",
      "19735  ...    0.402 -0.238 -1.563  1.015  0.278  1.053  1.407  1.504 -0.771   \n",
      "19736  ...   -0.929 -0.921  0.310  1.956  0.017  0.110 -0.273 -0.322 -0.405   \n",
      "19737  ...   -2.089  1.203  0.523  0.300  0.815 -0.587  1.086  0.150 -2.868   \n",
      "19738  ...   -1.188 -0.531 -0.564  0.168 -0.229  0.511 -1.267 -0.787 -0.415   \n",
      "19739  ...    0.187  0.042  0.887  0.431  0.193 -0.465  0.980  0.373 -0.180   \n",
      "19740  ...   -0.123 -1.488 -0.232 -0.293  0.875 -1.975 -1.544  1.462  0.603   \n",
      "19741  ...    0.958 -0.441 -0.624  0.665 -0.214  1.758 -1.723  1.321 -1.520   \n",
      "19742  ...    0.174 -2.001 -2.353  0.993 -1.622 -1.227  0.025  0.768  1.080   \n",
      "19743  ...   -0.025 -1.766 -0.695  1.096  0.791 -0.430 -0.101  0.379 -0.534   \n",
      "19744  ...   -1.317 -0.137 -1.104 -1.559  0.291  0.776 -1.013  0.869 -0.509   \n",
      "19745  ...    0.495  1.021  0.126 -0.353 -0.092  0.996 -0.381 -0.748  1.567   \n",
      "19746  ...   -0.246 -0.205 -0.368  1.589  0.389 -0.496 -0.940 -1.457 -1.152   \n",
      "19747  ...   -0.008 -1.283 -0.574  0.465 -0.663  0.486 -0.375  1.546  0.759   \n",
      "19748  ...   -0.228 -0.814  1.008 -0.152 -1.831 -0.980 -1.054  1.319 -0.181   \n",
      "19749  ...   -1.201 -1.633  0.448 -0.511 -0.516  1.565  0.318 -0.268  0.133   \n",
      "\n",
      "         299  \n",
      "0      0.979  \n",
      "1     -0.761  \n",
      "2      2.463  \n",
      "3     -1.529  \n",
      "4      0.825  \n",
      "5      0.411  \n",
      "6      2.340  \n",
      "7      0.065  \n",
      "8     -0.687  \n",
      "9      1.033  \n",
      "10    -0.822  \n",
      "11     1.074  \n",
      "12    -1.091  \n",
      "13    -2.213  \n",
      "14    -0.224  \n",
      "15    -1.346  \n",
      "16     0.407  \n",
      "17    -0.134  \n",
      "18     0.048  \n",
      "19    -0.540  \n",
      "20     0.422  \n",
      "21     1.996  \n",
      "22    -1.752  \n",
      "23    -1.315  \n",
      "24    -0.854  \n",
      "25     1.384  \n",
      "26     0.523  \n",
      "27    -0.075  \n",
      "28    -0.508  \n",
      "29     0.358  \n",
      "...      ...  \n",
      "19720 -0.050  \n",
      "19721 -1.056  \n",
      "19722 -0.173  \n",
      "19723 -0.677  \n",
      "19724  0.416  \n",
      "19725 -0.291  \n",
      "19726 -0.271  \n",
      "19727  0.919  \n",
      "19728  1.293  \n",
      "19729  0.534  \n",
      "19730  1.041  \n",
      "19731  1.351  \n",
      "19732 -2.179  \n",
      "19733 -1.089  \n",
      "19734  0.290  \n",
      "19735 -0.297  \n",
      "19736 -1.830  \n",
      "19737 -0.643  \n",
      "19738 -0.281  \n",
      "19739 -0.509  \n",
      "19740  0.803  \n",
      "19741  0.824  \n",
      "19742 -1.762  \n",
      "19743  0.560  \n",
      "19744  0.624  \n",
      "19745  1.165  \n",
      "19746  0.937  \n",
      "19747  0.519  \n",
      "19748  0.689  \n",
      "19749  0.826  \n",
      "\n",
      "[19750 rows x 301 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
